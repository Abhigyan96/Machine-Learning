{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GKAhl-n9s4Zv"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iPVgIqF8tKvr"
   },
   "outputs": [],
   "source": [
    "# To remove the scientific notation from numpy arrays\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WBxbHbUQtMxw"
   },
   "outputs": [],
   "source": [
    "premonsoon_data = pd.read_csv('/content/ALL_DCF.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "__saOHoitOw5"
   },
   "outputs": [],
   "source": [
    "premonsoon_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xS5nfMdotQ_j"
   },
   "outputs": [],
   "source": [
    "premonsoon_data.corr(method ='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XMdMI4zjttd5"
   },
   "outputs": [],
   "source": [
    "# Separate Target Variable and Predictor Variables\n",
    "TargetVariable=['Output']\n",
    "Predictors=['Smap_S1','DC','TWI', 'Filled_DEM', 'NDVI_L9', 'LST', 'SMI','Sigma0-VV','Sigma0-VH','TM','HM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZTZaNMSzuUaq"
   },
   "outputs": [],
   "source": [
    "X = premonsoon_data[Predictors].values\n",
    "Y = premonsoon_data[TargetVariable].values\n",
    "\n",
    "### Sandardization of data ###\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "PredictorScaler=StandardScaler()\n",
    "TargetVarScaler=StandardScaler()\n",
    "\n",
    "# Storing the fit object for later reference\n",
    "PredictorScalerFit=PredictorScaler.fit(X)\n",
    "TargetVarScalerFit=TargetVarScaler.fit(Y)\n",
    "\n",
    "# Generating the standardized values of X and y\n",
    "x=PredictorScalerFit.transform(X)\n",
    "y=TargetVarScalerFit.transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xbuz0Q-mud76",
    "outputId": "2de734de-75c8-42b8-fcab-5bfd05a89a84"
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=5)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mcCNOxKSujIj",
    "outputId": "d1f587bd-61f4-4490-f86f-c43b395e5552"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6rIY9Ivvup4F",
    "outputId": "3e0b41d7-9bb9-4c04-9da3-d90e6a25afad"
   },
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn import metrics\n",
    "from math import sqrt\n",
    "\n",
    "# Defining a function to find the best parameters for ANN\n",
    "def FunctionFindBestParams(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    # Defining the list of hyper parameters to try\n",
    "    batch_size_list=[5, 10, 15, 20]\n",
    "    epoch_list  =   [5, 10, 50, 100]\n",
    "\n",
    "    import pandas as pd\n",
    "    SearchResultsData=pd.DataFrame(columns=['TrialNumber', 'Parameters', 'Accuracy'])\n",
    "\n",
    "    # initializing the trials\n",
    "    TrialNumber=0\n",
    "    for batch_size_trial in batch_size_list:\n",
    "        for epochs_trial in epoch_list:\n",
    "            TrialNumber+=1\n",
    "            # create ANN model\n",
    "            model = Sequential()\n",
    "            # Defining the first layer of the model\n",
    "            model.add(Dense(units=20, input_dim=X_train.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "            # Defining the Second layer of the model\n",
    "            model.add(Dense(units=25, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "            model.add(Dense(units=20, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "            # The output neuron is a single fully connected node\n",
    "            # Since we will be predicting a single number\n",
    "            model.add(Dense(1, kernel_initializer='normal'))\n",
    "\n",
    "            # Compiling the model\n",
    "            model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "            # Fitting the ANN to the Training set\n",
    "            model.fit(X_train, y_train ,batch_size = batch_size_trial, epochs = epochs_trial, verbose=0)\n",
    "\n",
    "            # printing the results of the current iteration\n",
    "            print(TrialNumber, 'Parameters:','batch_size:', batch_size_trial,'-', 'epochs:',epochs_trial, 'R2', metrics.r2_score(y_test, model.predict(X_test)), 'RMSE', sqrt(metrics.mean_squared_error(y_test, model.predict(X_test))))\n",
    "\n",
    "            SearchResultsData=SearchResultsData.append(pd.DataFrame(data=[[TrialNumber, str(batch_size_trial)+'-'+str(epochs_trial), metrics.r2_score(y_test, model.predict(X_test)), sqrt(metrics.mean_squared_error(y_test, model.predict(X_test)))]],\n",
    "                                                                    columns=['TrialNumber', 'Parameters', 'R2', 'RMSE'] ))\n",
    "    return(SearchResultsData)\n",
    "\n",
    "\n",
    "######################################################\n",
    "# Calling the function\n",
    "ResultsData=FunctionFindBestParams(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YOebaSMmv_l_"
   },
   "outputs": [],
   "source": [
    "# 3 Parameters: batch_size: 5 - epochs: 50 R2 0.6805536606970652 RMSE 0.6088032779263932"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
